# This file was created by the command:
# steps/nnet3/xconfig_to_configs.py --xconfig-file exp_learning/inside/chain/tdnnf_Augment_128_64_14_0.2_yukang/configs/network.xconfig --config-dir exp_learning/inside/chain/tdnnf_Augment_128_64_14_0.2_yukang/configs/
# It contains the same content as ./xconfig but it was parsed,
# default config values were set, 
# and Descriptors (input=xxx) were normalized.
# See also ./xconfig.expanded.1

input name=ivector dim=100
input name=input dim=40
fixed-affine-layer name=lda affine-transform-file=exp_learning/inside/chain/tdnnf_Augment_128_64_14_0.2_yukang/configs/lda.mat delay=0 dim=220 input=Append(Offset(input, -1), input, Offset(input, 1), ReplaceIndex(ivector, t, 0)) write-init-config=True
relu-batchnorm-dropout-layer name=tdnn1 add-log-stddev=False bias-stddev= bottleneck-dim=-1 dim=128 dropout-per-dim=True dropout-per-dim-continuous=True dropout-proportion=0.5 input=lda l2-regularize=0.0005 learning-rate-factor= max-change=0.75 ng-affine-options= ng-linear-options= self-repair-scale=1e-05 target-rms=1.0
tdnnf-layer name=tdnnf2 bottleneck-dim=64 bypass-scale=0.75 context=default dim=128 dropout-proportion=0.5 input=tdnn1 l2-regularize=0.0005 max-change=0.75 self-repair-scale=1e-05 time-stride=14
tdnnf-layer name=tdnnf3 bottleneck-dim=64 bypass-scale=0.75 context=default dim=128 dropout-proportion=0.5 input=tdnnf2 l2-regularize=0.0005 max-change=0.75 self-repair-scale=1e-05 time-stride=14
tdnnf-layer name=tdnnf4 bottleneck-dim=64 bypass-scale=0.75 context=default dim=128 dropout-proportion=0.5 input=tdnnf3 l2-regularize=0.0005 max-change=0.75 self-repair-scale=1e-05 time-stride=14
tdnnf-layer name=tdnnf5 bottleneck-dim=64 bypass-scale=0.75 context=default dim=128 dropout-proportion=0.5 input=tdnnf4 l2-regularize=0.0005 max-change=0.75 self-repair-scale=1e-05 time-stride=14
tdnnf-layer name=tdnnf6 bottleneck-dim=64 bypass-scale=0.75 context=default dim=128 dropout-proportion=0.5 input=tdnnf5 l2-regularize=0.0005 max-change=0.75 self-repair-scale=1e-05 time-stride=14
tdnnf-layer name=tdnnf7 bottleneck-dim=64 bypass-scale=0.75 context=default dim=128 dropout-proportion=0.5 input=tdnnf6 l2-regularize=0.0005 max-change=0.75 self-repair-scale=1e-05 time-stride=14
tdnnf-layer name=tdnnf8 bottleneck-dim=64 bypass-scale=0.75 context=default dim=128 dropout-proportion=0.5 input=tdnnf7 l2-regularize=0.0005 max-change=0.75 self-repair-scale=1e-05 time-stride=14
tdnnf-layer name=tdnnf9 bottleneck-dim=64 bypass-scale=0.75 context=default dim=128 dropout-proportion=0.5 input=tdnnf8 l2-regularize=0.0005 max-change=0.75 self-repair-scale=1e-05 time-stride=14
tdnnf-layer name=tdnnf10 bottleneck-dim=64 bypass-scale=0.75 context=default dim=128 dropout-proportion=0.5 input=tdnnf9 l2-regularize=0.0005 max-change=0.75 self-repair-scale=1e-05 time-stride=14
tdnnf-layer name=tdnnf11 bottleneck-dim=64 bypass-scale=0.75 context=default dim=128 dropout-proportion=0.5 input=tdnnf10 l2-regularize=0.0005 max-change=0.75 self-repair-scale=1e-05 time-stride=14
tdnnf-layer name=tdnnf12 bottleneck-dim=64 bypass-scale=0.75 context=default dim=128 dropout-proportion=0.5 input=tdnnf11 l2-regularize=0.0005 max-change=0.75 self-repair-scale=1e-05 time-stride=14
tdnnf-layer name=tdnnf13 bottleneck-dim=64 bypass-scale=0.75 context=default dim=128 dropout-proportion=0.5 input=tdnnf12 l2-regularize=0.0005 max-change=0.75 self-repair-scale=1e-05 time-stride=14
linear-component name=prefinal-l dim=64 input=tdnnf13 l2-regularize=0.005 learning-rate-factor= max-change=0.75 orthonormal-constraint=-1.0 param-stddev=
prefinal-layer name=prefinal-chain big-dim=128 input=prefinal-l l2-regularize=0.0005 max-change=0.75 self-repair-scale=1e-05 small-dim=64
output-layer name=output bias-stddev=0.0 bottleneck-dim=-1 dim=4040 include-log-softmax=False input=prefinal-chain l2-regularize=0.00005 learning-rate-factor= max-change=1.5 ng-affine-options= ng-linear-options= objective-type=linear orthonormal-constraint=1.0 output-delay=0 param-stddev=0.0
prefinal-layer name=prefinal-xent big-dim=128 input=prefinal-l l2-regularize=0.0005 max-change=0.75 self-repair-scale=1e-05 small-dim=64
output-layer name=output-xent bias-stddev=0.0 bottleneck-dim=-1 dim=4040 include-log-softmax=True input=prefinal-xent l2-regularize=0.00005 learning-rate-factor=5.0 max-change=1.5 ng-affine-options= ng-linear-options= objective-type=linear orthonormal-constraint=1.0 output-delay=0 param-stddev=0.0
